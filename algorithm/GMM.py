import numpy as np
from typing import Tuple, List

import cv2
from sklearn.mixture import GaussianMixture, BayesianGaussianMixture
from skimage.color import label2rgb
from skimage import img_as_ubyte
from skimage.measure import block_reduce
import pandas as pd

from .basic import adjust2gray, fgPts


def gmm(data: np.ndarray, n: int, method: str = 'default') -> \
        Tuple[List[int], List[int]]:
    """
    :param data: list of input
    :param n: number of components
    :param method: 'default' or 'bayesian'
    :return: (labels, means)
    """
    # To avoid error, the number of components should be
    # no more than the length of input data.
    noc = min(len(data), n)
    if method.lower() == 'bayesian':
        model = BayesianGaussianMixture(n_components=noc)
        model.fit(data)
    else:
        model = GaussianMixture(n_components=noc)
        model.fit(data)
    return model.predict(data), model.means_


def global_gmm(image: np.ndarray, mask: np.ndarray,
               n: int, patch: Tuple[int, int]) -> \
        Tuple[np.ndarray, np.ndarray, np.ndarray, pd.DataFrame]:
    """
    :param image: color image, 3D numpy array
    :param mask: binary image, 2D binary numpy array
    :param n: number of components
    :param patch: size of block
    :return: (3D numpy array, 2D numpy array, pandas data frame)
    Solve GMM for the image histogram, iteratively find
    the minimalist mean of GMM models and separate the
    corresponding points.
    """
    # Convert color image to grayscale.
    # Strengthen staining signals and remove false positive patterns.
    image_adjusted = adjust2gray(image)
    # Down sample the images and masks to reduce calculation.
    image_down = block_reduce(image_adjusted, patch,
                              np.mean, 255).astype(np.uint8)
    mask_down = block_reduce(mask, patch, np.min)
    mask_out = mask_down.copy()
    global_mean = int(np.mean(image_down[mask_down > 0]))
    label_out = np.zeros(mask_down.shape, dtype=np.uint8)
    nol = 0  # The count of labels.
    model_out = pd.DataFrame(columns=[0, 1])
    while True:
        # Retrieve current foreground points.
        pts = fgPts(mask_down)
        # The model fits the foreground pixels' intensity.
        model_input = np.array([[image_down[tuple(p)]
                                 for p in pts]]).transpose()
        labels, means = gmm(model_input, n)
        min_cluster, min_mean = np.argmin(means), min(means)
        # When the minimum mean reach the global mean, break the loop.
        if min_mean >= global_mean:
            break
        # Otherwise, label the points in the output mask,
        # and dump them in the next run.
        stain_pts = pts[labels == min_cluster]
        nol += 1
        for p in stain_pts:  #
            mask_down[tuple(p)] = 0
            label_out[tuple(p)] = nol
        model_out = model_out.append([[nol, min_mean]])
    model_out.columns = ['label', 'mean']
    model_out = model_out.set_index('label')
    # Label the output image.
    height, width = image.shape[:2]
    label_up = cv2.resize(label_out, (width, height),
                          interpolation=cv2.INTER_NEAREST)
    image_out = img_as_ubyte(label2rgb(label_up, image, bg_label=0))
    return image_out, mask_out, label_out, model_out


def local_gmm(image: np.array, mask: np.ndarray,
              global_model: pd.DataFrame, n: int) -> \
        Tuple[np.ndarray, np.ndarray, pd.DataFrame]:
    """
    :type mask: numpy.array
    :param image: bgr image, 3D numpy array
    :param mask: binary image, 2D numpy array
    :param global_model: parameters of global gmm, pandas data frame
    :param n: maximum number of components for the bayesian algorithm
    :return: (image, mask, model)
    Solve GMM for points' local distribution within
    each grayscale level generated by the global model.
    """
    label_out = np.zeros(mask.shape, dtype=np.uint8)
    model_out = pd.DataFrame(columns=['label', 'mean'])
    # Iterate over different grayscale levels in the global model.
    for i, mean in zip(global_model.index, global_model['mean']):
        pts = fgPts(mask == i)  # Retrieve points with a specific label.
        labels = gmm(pts, n, 'bayesian')[0]
        # Adjust labels from 0..n-1 to 1..n.
        # Because labels can be discontinuous.
        levels = np.unique(labels)
        labels = [np.where(levels == i)[0][0] + 1 for i in labels]
        # Label the areas on the output mask.
        start = np.max(label_out)
        for p, label in zip(pts, labels):
            label_out[tuple(p)] = start + label
        model = pd.DataFrame({'label': [*range(start, start + max(labels))],
                              'mean': [mean] * max(labels)})
        model_out = model_out.append(model)
    model_out = model_out.set_index('label')
    # Label the output image
    height, width = image.shape[:2]
    mask_up = cv2.resize(label_out, (width, height),
                         interpolation=cv2.INTER_NEAREST)
    image_out = img_as_ubyte(label2rgb(mask_up, image, bg_label=0))
    return image_out, label_out, model_out
